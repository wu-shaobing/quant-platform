# åç«¯æŠ€æœ¯æ¶æ„è¯¦ç»†è®¾è®¡

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„æ€»è§ˆ

### æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "å®¢æˆ·ç«¯å±‚"
        A[Vue3å‰ç«¯åº”ç”¨]
        B[ç§»åŠ¨ç«¯App]
        C[ç¬¬ä¸‰æ–¹APIå®¢æˆ·ç«¯]
    end
    
    subgraph "æ¥å…¥å±‚"
        D[Nginxè´Ÿè½½å‡è¡¡]
        E[APIç½‘å…³]
        F[WebSocketç½‘å…³]
    end
    
    subgraph "åº”ç”¨å±‚"
        G[FastAPIæœåŠ¡]
        H[WebSocketæœåŠ¡]
        I[Celery Worker]
    end
    
    subgraph "ä¸šåŠ¡å±‚"
        J[è®¤è¯æœåŠ¡]
        K[äº¤æ˜“æœåŠ¡]
        L[è¡Œæƒ…æœåŠ¡]
        M[å›æµ‹æœåŠ¡]
        N[é£æ§æœåŠ¡]
    end
    
    subgraph "æ•°æ®å±‚"
        O[PostgreSQLä¸»åº“]
        P[PostgreSQLä»åº“]
        Q[Redisé›†ç¾¤]
        R[TimescaleDB]
    end
    
    subgraph "å¤–éƒ¨æ¥å£"
        S[CTPæœŸè´§æ¥å£]
        T[è¡Œæƒ…æ•°æ®æº]
        U[ç¬¬ä¸‰æ–¹æœåŠ¡]
    end
    
    A --> D
    B --> D
    C --> E
    D --> G
    D --> H
    E --> G
    F --> H
    G --> J
    G --> K
    G --> L
    G --> M
    G --> N
    H --> L
    I --> M
    I --> N
    J --> O
    K --> O
    L --> Q
    L --> R
    M --> P
    N --> O
    K --> S
    L --> T
    G --> U
```

## ğŸ¯ æ¶æ„è®¾è®¡åŸåˆ™

### 1. åˆ†å±‚æ¶æ„åŸåˆ™
- **æ¥å…¥å±‚**: ç»Ÿä¸€å…¥å£ï¼Œè´Ÿè½½å‡è¡¡ï¼Œåè®®è½¬æ¢
- **åº”ç”¨å±‚**: ä¸šåŠ¡é€»è¾‘å¤„ç†ï¼ŒAPIæœåŠ¡æä¾›
- **æœåŠ¡å±‚**: é¢†åŸŸä¸šåŠ¡æœåŠ¡ï¼Œæ ¸å¿ƒåŠŸèƒ½å®ç°
- **æ•°æ®å±‚**: æ•°æ®æŒä¹…åŒ–ï¼Œç¼“å­˜ç®¡ç†

### 2. å¾®æœåŠ¡è®¾è®¡åŸåˆ™
- **å•ä¸€èŒè´£**: æ¯ä¸ªæœåŠ¡ä¸“æ³¨ç‰¹å®šä¸šåŠ¡é¢†åŸŸ
- **æœåŠ¡è‡ªæ²»**: ç‹¬ç«‹éƒ¨ç½²ã€ç‹¬ç«‹æ‰©å±•
- **æ¥å£æ ‡å‡†**: ç»Ÿä¸€APIè§„èŒƒï¼Œæ ‡å‡†åŒ–é€šä¿¡
- **æ•…éšœéš”ç¦»**: æœåŠ¡é—´æ•…éšœä¸ç›¸äº’å½±å“

### 3. é«˜å¯ç”¨è®¾è®¡åŸåˆ™
- **æ— å•ç‚¹æ•…éšœ**: å…³é”®ç»„ä»¶å¤šå®ä¾‹éƒ¨ç½²
- **æ•…éšœå¿«é€Ÿæ¢å¤**: è‡ªåŠ¨é‡å¯ã€å¥åº·æ£€æŸ¥
- **æ•°æ®ä¸€è‡´æ€§**: äº‹åŠ¡ä¿è¯ã€æœ€ç»ˆä¸€è‡´æ€§
- **é™çº§æœºåˆ¶**: æ ¸å¿ƒåŠŸèƒ½ä¼˜å…ˆä¿éšœ

## ğŸ”§ æŠ€æœ¯é€‰å‹è¯¦è§£

### 1. Webæ¡†æ¶ - FastAPI

#### é€‰æ‹©ç†ç”±
```python
# é«˜æ€§èƒ½å¼‚æ­¥æ¡†æ¶
from fastapi import FastAPI, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
import asyncio

app = FastAPI(
    title="Quant Trading API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# è‡ªåŠ¨APIæ–‡æ¡£ç”Ÿæˆ
@app.get("/market/kline/{symbol}")
async def get_kline(
    symbol: str,
    period: str = "1d",
    limit: int = 500
) -> List[KLineData]:
    """è·å–Kçº¿æ•°æ® - è‡ªåŠ¨ç”ŸæˆOpenAPIæ–‡æ¡£"""
    return await market_service.get_kline_data(symbol, period, limit)
```

#### æŠ€æœ¯ä¼˜åŠ¿
- **å¼‚æ­¥æ€§èƒ½**: åŸºäºASGIï¼Œæ”¯æŒé«˜å¹¶å‘
- **ç±»å‹å®‰å…¨**: Pydanticæ•°æ®éªŒè¯
- **è‡ªåŠ¨æ–‡æ¡£**: OpenAPI/Swaggerè‡ªåŠ¨ç”Ÿæˆ
- **ç°ä»£Python**: æ”¯æŒPython 3.7+ æ–°ç‰¹æ€§

### 2. æ•°æ®å¤„ç† - NumPy + Pandas

#### é‡‘èæ•°æ®å¤„ç†ä¼˜åŒ–
```python
import numpy as np
import pandas as pd
from numba import jit

class TechnicalIndicators:
    @staticmethod
    @jit(nopython=True)
    def sma_numba(prices: np.ndarray, window: int) -> np.ndarray:
        """ä½¿ç”¨NumbaåŠ é€Ÿçš„ç®€å•ç§»åŠ¨å¹³å‡"""
        result = np.empty_like(prices)
        result[:window-1] = np.nan
        
        for i in range(window-1, len(prices)):
            result[i] = np.mean(prices[i-window+1:i+1])
        
        return result
    
    @staticmethod
    def calculate_indicators(df: pd.DataFrame) -> pd.DataFrame:
        """å‘é‡åŒ–æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
        # ç§»åŠ¨å¹³å‡çº¿
        for period in [5, 10, 20, 60]:
            df[f'MA{period}'] = df['close'].rolling(period).mean()
        
        # MACD
        exp12 = df['close'].ewm(span=12).mean()
        exp26 = df['close'].ewm(span=26).mean()
        df['MACD'] = exp12 - exp26
        df['Signal'] = df['MACD'].ewm(span=9).mean()
        df['Histogram'] = df['MACD'] - df['Signal']
        
        # RSI
        delta = df['close'].diff()
        gain = delta.where(delta > 0, 0).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        return df
```

#### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
```python
# å†…å­˜ä¼˜åŒ–
def optimize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """ä¼˜åŒ–DataFrameå†…å­˜ä½¿ç”¨"""
    for col in df.columns:
        if df[col].dtype == 'float64':
            df[col] = pd.to_numeric(df[col], downcast='float')
        elif df[col].dtype == 'int64':
            df[col] = pd.to_numeric(df[col], downcast='integer')
    
    return df

# åˆ†å—å¤„ç†å¤§æ•°æ®
def process_large_dataset(file_path: str, chunk_size: int = 10000):
    """åˆ†å—å¤„ç†å¤§å‹æ•°æ®é›†"""
    results = []
    
    for chunk in pd.read_csv(file_path, chunksize=chunk_size):
        # å¤„ç†æ¯ä¸ªæ•°æ®å—
        processed_chunk = TechnicalIndicators.calculate_indicators(chunk)
        results.append(processed_chunk)
    
    return pd.concat(results, ignore_index=True)
```

### 3. æ•°æ®å­˜å‚¨æ¶æ„

#### PostgreSQL + TimescaleDB
```sql
-- æ—¶åºæ•°æ®è¡¨è®¾è®¡
CREATE TABLE market_data (
    id BIGSERIAL PRIMARY KEY,
    symbol VARCHAR(32) NOT NULL,
    timestamp TIMESTAMPTZ NOT NULL,
    open DECIMAL(18,4) NOT NULL,
    high DECIMAL(18,4) NOT NULL,
    low DECIMAL(18,4) NOT NULL,
    close DECIMAL(18,4) NOT NULL,
    volume BIGINT NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- åˆ›å»ºTimescaleDBè¶…è¡¨
SELECT create_hypertable('market_data', 'timestamp');

-- åˆ›å»ºç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
CREATE INDEX idx_market_data_symbol_time ON market_data (symbol, timestamp DESC);
CREATE INDEX idx_market_data_symbol ON market_data USING HASH (symbol);

-- æ•°æ®ä¿ç•™ç­–ç•¥
SELECT add_retention_policy('market_data', INTERVAL '2 years');
```

#### Redisç¼“å­˜ç­–ç•¥
```python
import redis
import json
from typing import Optional, Any
import pickle

class CacheManager:
    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url, decode_responses=True)
        self.binary_redis = redis.from_url(redis_url, decode_responses=False)
    
    async def get_market_data(self, symbol: str, period: str) -> Optional[pd.DataFrame]:
        """è·å–ç¼“å­˜çš„è¡Œæƒ…æ•°æ®"""
        cache_key = f"market_data:{symbol}:{period}"
        
        try:
            cached_data = self.binary_redis.get(cache_key)
            if cached_data:
                return pickle.loads(cached_data)
        except Exception as e:
            logger.error(f"Cache get error: {e}")
        
        return None
    
    async def set_market_data(self, symbol: str, period: str, data: pd.DataFrame, expire: int = 300):
        """ç¼“å­˜è¡Œæƒ…æ•°æ®"""
        cache_key = f"market_data:{symbol}:{period}"
        
        try:
            serialized_data = pickle.dumps(data)
            self.binary_redis.setex(cache_key, expire, serialized_data)
        except Exception as e:
            logger.error(f"Cache set error: {e}")
    
    async def publish_realtime_data(self, channel: str, data: dict):
        """å‘å¸ƒå®æ—¶æ•°æ®"""
        try:
            self.redis.publish(channel, json.dumps(data))
        except Exception as e:
            logger.error(f"Publish error: {e}")
```

### 4. CTPæ¥å£é›†æˆæ¶æ„

#### CTPå°è£…è®¾è®¡
```python
import asyncio
from typing import Dict, Callable, Optional
from dataclasses import dataclass
from enum import Enum

@dataclass
class CTPConfig:
    broker_id: str
    user_id: str
    password: str
    md_address: str
    td_address: str

class OrderSide(Enum):
    BUY = "0"
    SELL = "1"

class CTPWrapper:
    def __init__(self, config: CTPConfig):
        self.config = config
        self.md_api = None
        self.td_api = None
        self.callbacks: Dict[str, Callable] = {}
        self.order_refs: Dict[str, str] = {}
        
    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ–CTPè¿æ¥"""
        await asyncio.gather(
            self._init_market_data(),
            self._init_trading()
        )
    
    async def _init_market_data(self):
        """åˆå§‹åŒ–è¡Œæƒ…æ¥å£"""
        self.md_api = MdApi(self)
        self.md_api.RegisterFront(self.config.md_address)
        self.md_api.Init()
        
        # ç­‰å¾…è¿æ¥æˆåŠŸ
        await self._wait_for_connection('md')
    
    async def _init_trading(self):
        """åˆå§‹åŒ–äº¤æ˜“æ¥å£"""
        self.td_api = TraderApi(self)
        self.td_api.RegisterFront(self.config.td_address)
        self.td_api.SubscribePrivateTopic(0)
        self.td_api.SubscribePublicTopic(0)
        self.td_api.Init()
        
        # ç­‰å¾…è¿æ¥æˆåŠŸ
        await self._wait_for_connection('td')
    
    def register_callback(self, event: str, callback: Callable):
        """æ³¨å†Œäº‹ä»¶å›è°ƒ"""
        self.callbacks[event] = callback
    
    async def place_order(self, symbol: str, side: OrderSide, price: float, volume: int) -> str:
        """å¼‚æ­¥ä¸‹å•"""
        order_ref = self._generate_order_ref()
        
        # æ„é€ ä¸‹å•è¯·æ±‚
        order_request = {
            'InstrumentID': symbol,
            'Direction': side.value,
            'LimitPrice': price,
            'VolumeTotalOriginal': volume,
            'OrderRef': order_ref,
            'CombOffsetFlag': '0',  # å¼€ä»“
            'CombHedgeFlag': '1',   # æŠ•æœº
            'TimeCondition': '3',   # å½“æ—¥æœ‰æ•ˆ
            'VolumeCondition': '1', # ä»»ä½•æ•°é‡
            'MinVolume': 1,
            'ContingentCondition': '1',  # ç«‹å³
            'ForceCloseReason': '0',     # éå¼ºå¹³
            'IsAutoSuspend': 0,
            'UserForceClose': 0
        }
        
        # æäº¤è®¢å•
        self.td_api.ReqOrderInsert(order_request)
        self.order_refs[order_ref] = symbol
        
        return order_ref
    
    def _generate_order_ref(self) -> str:
        """ç”Ÿæˆå”¯ä¸€è®¢å•å¼•ç”¨"""
        import time
        return f"{self.config.user_id}_{int(time.time() * 1000000) % 1000000}"
    
    # CTPå›è°ƒå¤„ç†
    def OnFrontConnected(self):
        """è¿æ¥æˆåŠŸå›è°ƒ"""
        if 'connected' in self.callbacks:
            asyncio.create_task(self.callbacks['connected']())
    
    def OnRtnDepthMarketData(self, data):
        """è¡Œæƒ…æ•°æ®å›è°ƒ"""
        if 'market_data' in self.callbacks:
            asyncio.create_task(self.callbacks['market_data'](data))
    
    def OnRtnOrder(self, data):
        """è®¢å•çŠ¶æ€å›è°ƒ"""
        if 'order_update' in self.callbacks:
            asyncio.create_task(self.callbacks['order_update'](data))
    
    def OnRtnTrade(self, data):
        """æˆäº¤å›æŠ¥å›è°ƒ"""
        if 'trade_update' in self.callbacks:
            asyncio.create_task(self.callbacks['trade_update'](data))
```

### 5. å¼‚æ­¥ä»»åŠ¡æ¶æ„ - Celery

#### Celeryé…ç½®ä¼˜åŒ–
```python
from celery import Celery
from kombu import Queue
import os

# Celeryåº”ç”¨é…ç½®
celery_app = Celery("quant-backend")

# é…ç½®ä¼˜åŒ–
celery_app.conf.update(
    # åºåˆ—åŒ–
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    
    # æ—¶åŒº
    timezone='Asia/Shanghai',
    enable_utc=True,
    
    # ä»»åŠ¡è·¯ç”±
    task_routes={
        'app.tasks.backtest_tasks.*': {'queue': 'backtest'},
        'app.tasks.data_tasks.*': {'queue': 'data'},
        'app.tasks.report_tasks.*': {'queue': 'report'},
    },
    
    # é˜Ÿåˆ—é…ç½®
    task_queues=(
        Queue('backtest', routing_key='backtest', priority=5),
        Queue('data', routing_key='data', priority=8),
        Queue('report', routing_key='report', priority=3),
        Queue('default', routing_key='default', priority=1),
    ),
    
    # ä»»åŠ¡æ‰§è¡Œé…ç½®
    task_acks_late=True,
    worker_prefetch_multiplier=1,
    task_reject_on_worker_lost=True,
    
    # ç»“æœåç«¯
    result_backend=os.getenv('CELERY_RESULT_BACKEND'),
    result_expires=3600,
    
    # ç›‘æ§
    worker_send_task_events=True,
    task_send_sent_event=True,
)

# ä»»åŠ¡è£…é¥°å™¨
@celery_app.task(bind=True, max_retries=3)
def backtest_task(self, backtest_id: str, params: dict):
    """å›æµ‹ä»»åŠ¡"""
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.update_state(
            state='PROGRESS',
            meta={'progress': 0, 'status': 'Starting backtest...'}
        )
        
        # æ‰§è¡Œå›æµ‹é€»è¾‘
        result = run_backtest_logic(params, progress_callback=self.update_state)
        
        return {
            'status': 'SUCCESS',
            'result': result,
            'backtest_id': backtest_id
        }
        
    except Exception as exc:
        # é‡è¯•æœºåˆ¶
        if self.request.retries < self.max_retries:
            raise self.retry(countdown=60, exc=exc)
        
        # å¤±è´¥å¤„ç†
        self.update_state(
            state='FAILURE',
            meta={'error': str(exc), 'backtest_id': backtest_id}
        )
        raise
```

### 4. WebSocketå®æ—¶é€šä¿¡å±‚

#### æ¶æ„è®¾è®¡
```python
# app/websocket/manager.py
from fastapi import WebSocket
from typing import Dict, List, Set
import json
import asyncio
from datetime import datetime

class WebSocketManager:
    def __init__(self):
        # è¿æ¥ç®¡ç†
        self.active_connections: Dict[str, WebSocket] = {}
        self.user_connections: Dict[int, Set[str]] = {}
        self.subscriptions: Dict[str, Set[str]] = {}  # è®¢é˜…ç®¡ç†
        
    async def connect(self, websocket: WebSocket, connection_id: str):
        """å»ºç«‹WebSocketè¿æ¥"""
        await websocket.accept()
        self.active_connections[connection_id] = websocket
        
    async def disconnect(self, connection_id: str):
        """æ–­å¼€WebSocketè¿æ¥"""
        if connection_id in self.active_connections:
            del self.active_connections[connection_id]
            
        # æ¸…ç†ç”¨æˆ·è¿æ¥æ˜ å°„
        for user_id, connections in self.user_connections.items():
            connections.discard(connection_id)
            
        # æ¸…ç†è®¢é˜…
        for channel, subscribers in self.subscriptions.items():
            subscribers.discard(connection_id)
    
    async def authenticate_connection(self, connection_id: str, user_id: int):
        """è®¤è¯WebSocketè¿æ¥"""
        if user_id not in self.user_connections:
            self.user_connections[user_id] = set()
        self.user_connections[user_id].add(connection_id)
    
    async def subscribe(self, connection_id: str, channel: str):
        """è®¢é˜…é¢‘é“"""
        if channel not in self.subscriptions:
            self.subscriptions[channel] = set()
        self.subscriptions[channel].add(connection_id)
    
    async def unsubscribe(self, connection_id: str, channel: str):
        """å–æ¶ˆè®¢é˜…"""
        if channel in self.subscriptions:
            self.subscriptions[channel].discard(connection_id)
    
    async def send_personal_message(self, user_id: int, message: dict):
        """å‘é€ä¸ªäººæ¶ˆæ¯"""
        if user_id in self.user_connections:
            connections = self.user_connections[user_id]
            for connection_id in connections.copy():
                websocket = self.active_connections.get(connection_id)
                if websocket:
                    try:
                        await websocket.send_text(json.dumps(message))
                    except Exception:
                        await self.disconnect(connection_id)
    
    async def broadcast_to_channel(self, channel: str, message: dict):
        """å‘é¢‘é“å¹¿æ’­æ¶ˆæ¯"""
        if channel in self.subscriptions:
            subscribers = self.subscriptions[channel].copy()
            for connection_id in subscribers:
                websocket = self.active_connections.get(connection_id)
                if websocket:
                    try:
                        await websocket.send_text(json.dumps(message))
                    except Exception:
                        await self.disconnect(connection_id)

# å…¨å±€WebSocketç®¡ç†å™¨å®ä¾‹
websocket_manager = WebSocketManager()
```

#### æ¶ˆæ¯å¤„ç†å™¨
```python
# app/websocket/handlers/auth.py
from app.websocket.manager import websocket_manager
from app.core.security import verify_token
import json

async def handle_auth_message(connection_id: str, message: dict):
    """å¤„ç†è®¤è¯æ¶ˆæ¯"""
    try:
        token = message.get('data', {}).get('token')
        if not token:
            await send_error(connection_id, "ç¼ºå°‘è®¤è¯ä»¤ç‰Œ")
            return
            
        # éªŒè¯JWTä»¤ç‰Œ
        payload = verify_token(token)
        user_id = payload.get('user_id')
        
        # è®¤è¯æˆåŠŸ
        await websocket_manager.authenticate_connection(connection_id, user_id)
        
        # å‘é€è®¤è¯æˆåŠŸå“åº”
        response = {
            "type": "auth_response",
            "data": {
                "status": "success",
                "user_id": user_id,
                "permissions": payload.get('permissions', [])
            },
            "timestamp": datetime.utcnow().isoformat()
        }
        
        websocket = websocket_manager.active_connections.get(connection_id)
        if websocket:
            await websocket.send_text(json.dumps(response))
            
    except Exception as e:
        await send_error(connection_id, f"è®¤è¯å¤±è´¥: {str(e)}")

async def send_error(connection_id: str, error_message: str):
    """å‘é€é”™è¯¯æ¶ˆæ¯"""
    error_response = {
        "type": "error",
        "data": {"message": error_message},
        "timestamp": datetime.utcnow().isoformat()
    }
    
    websocket = websocket_manager.active_connections.get(connection_id)
    if websocket:
        await websocket.send_text(json.dumps(error_response))
```

#### WebSocketè·¯ç”±
```python
# app/api/v1/websocket.py
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from app.websocket.manager import websocket_manager
from app.websocket.handlers import handle_message
import uuid
import json

router = APIRouter()

@router.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    connection_id = str(uuid.uuid4())
    
    try:
        await websocket_manager.connect(websocket, connection_id)
        
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            data = await websocket.receive_text()
            message = json.loads(data)
            
            # å¤„ç†æ¶ˆæ¯
            await handle_message(connection_id, message)
            
    except WebSocketDisconnect:
        await websocket_manager.disconnect(connection_id)
    except Exception as e:
        print(f"WebSocketé”™è¯¯: {e}")
        await websocket_manager.disconnect(connection_id)
```

### 7. å®‰å…¨æ¶æ„è®¾è®¡

#### JWTè®¤è¯ç³»ç»Ÿ
```python
from jose import JWTError, jwt
from passlib.context import CryptContext
from datetime import datetime, timedelta
from fastapi import HTTPException, status, Depends
from fastapi.security import OAuth2PasswordBearer

class SecurityManager:
    def __init__(self, secret_key: str, algorithm: str = "HS256"):
        self.secret_key = secret_key
        self.algorithm = algorithm
        self.pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
        self.oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")
    
    def verify_password(self, plain_password: str, hashed_password: str) -> bool:
        """éªŒè¯å¯†ç """
        return self.pwd_context.verify(plain_password, hashed_password)
    
    def get_password_hash(self, password: str) -> str:
        """ç”Ÿæˆå¯†ç å“ˆå¸Œ"""
        return self.pwd_context.hash(password)
    
    def create_access_token(self, data: dict, expires_delta: Optional[timedelta] = None):
        """åˆ›å»ºè®¿é—®ä»¤ç‰Œ"""
        to_encode = data.copy()
        
        if expires_delta:
            expire = datetime.utcnow() + expires_delta
        else:
            expire = datetime.utcnow() + timedelta(minutes=15)
        
        to_encode.update({"exp": expire})
        encoded_jwt = jwt.encode(to_encode, self.secret_key, algorithm=self.algorithm)
        
        return encoded_jwt
    
    async def get_current_user(self, token: str = Depends(oauth2_scheme)):
        """è·å–å½“å‰ç”¨æˆ·"""
        credentials_exception = HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )
        
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            username: str = payload.get("sub")
            if username is None:
                raise credentials_exception
                
            # éªŒè¯tokenæ˜¯å¦åœ¨é»‘åå•ä¸­
            if await self.is_token_blacklisted(token):
                raise credentials_exception
                
        except JWTError:
            raise credentials_exception
        
        # ä»æ•°æ®åº“è·å–ç”¨æˆ·ä¿¡æ¯
        user = await get_user_by_username(username)
        if user is None:
            raise credentials_exception
            
        return user
    
    async def is_token_blacklisted(self, token: str) -> bool:
        """æ£€æŸ¥tokenæ˜¯å¦åœ¨é»‘åå•ä¸­"""
        # ä»Redisæ£€æŸ¥tokené»‘åå•
        return await redis_client.sismember("token_blacklist", token)
    
    async def blacklist_token(self, token: str):
        """å°†tokenåŠ å…¥é»‘åå•"""
        # è§£ætokenè·å–è¿‡æœŸæ—¶é—´
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            exp = payload.get("exp")
            if exp:
                # è®¡ç®—å‰©ä½™æ—¶é—´
                expire_time = datetime.fromtimestamp(exp) - datetime.utcnow()
                if expire_time.total_seconds() > 0:
                    await redis_client.sadd("token_blacklist", token)
                    await redis_client.expire("token_blacklist", int(expire_time.total_seconds()))
        except JWTError:
            pass
```

#### APIé™æµä¸é˜²æŠ¤
```python
from fastapi import Request, HTTPException
from starlette.middleware.base import BaseHTTPMiddleware
import time
import asyncio

class RateLimitMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, calls: int = 100, period: int = 60):
        super().__init__(app)
        self.calls = calls
        self.period = period
        self.clients = {}
    
    async def dispatch(self, request: Request, call_next):
        client_ip = request.client.host
        current_time = time.time()
        
        # æ¸…ç†è¿‡æœŸè®°å½•
        if client_ip in self.clients:
            self.clients[client_ip] = [
                timestamp for timestamp in self.clients[client_ip]
                if current_time - timestamp < self.period
            ]
        else:
            self.clients[client_ip] = []
        
        # æ£€æŸ¥é™æµ
        if len(self.clients[client_ip]) >= self.calls:
            raise HTTPException(
                status_code=429,
                detail="Rate limit exceeded"
            )
        
        # è®°å½•è¯·æ±‚æ—¶é—´
        self.clients[client_ip].append(current_time)
        
        response = await call_next(request)
        return response

# é£æ§ä¸­é—´ä»¶
class RiskControlMiddleware(BaseHTTPMiddleware):
    def __init__(self, app):
        super().__init__(app)
        self.suspicious_patterns = [
            r'/api/v1/trading/order',  # äº¤æ˜“æ¥å£
            r'/api/v1/account/transfer',  # èµ„é‡‘è½¬è´¦
        ]
    
    async def dispatch(self, request: Request, call_next):
        # æ£€æŸ¥å¯ç–‘è¯·æ±‚æ¨¡å¼
        path = str(request.url.path)
        
        for pattern in self.suspicious_patterns:
            if re.match(pattern, path):
                # è®°å½•å¯ç–‘è¯·æ±‚
                await self.log_suspicious_request(request)
                
                # é¢å¤–éªŒè¯
                if not await self.verify_request_legitimacy(request):
                    raise HTTPException(
                        status_code=403,
                        detail="Request blocked by risk control"
                    )
        
        response = await call_next(request)
        return response
    
    async def log_suspicious_request(self, request: Request):
        """è®°å½•å¯ç–‘è¯·æ±‚"""
        log_data = {
            'ip': request.client.host,
            'path': str(request.url.path),
            'method': request.method,
            'user_agent': request.headers.get('user-agent'),
            'timestamp': datetime.utcnow().isoformat()
        }
        
        # å¼‚æ­¥è®°å½•åˆ°æ•°æ®åº“æˆ–æ—¥å¿—ç³»ç»Ÿ
        await log_to_security_system(log_data)
    
    async def verify_request_legitimacy(self, request: Request) -> bool:
        """éªŒè¯è¯·æ±‚åˆæ³•æ€§"""
        # å®ç°å…·ä½“çš„é£æ§é€»è¾‘
        # ä¾‹å¦‚ï¼šæ£€æŸ¥ç”¨æˆ·è¡Œä¸ºæ¨¡å¼ã€IPåœ°ç†ä½ç½®ç­‰
        return True
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. æ•°æ®åº“ä¼˜åŒ–
```python
# è¿æ¥æ± é…ç½®
from sqlalchemy.pool import QueuePool

engine = create_async_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=20,
    max_overflow=0,
    pool_pre_ping=True,
    pool_recycle=3600,
    echo=False
)

# æŸ¥è¯¢ä¼˜åŒ–
class OptimizedQueries:
    @staticmethod
    async def get_kline_data_optimized(
        db: AsyncSession,
        symbol: str,
        start_time: datetime,
        end_time: datetime,
        limit: int = 1000
    ):
        """ä¼˜åŒ–çš„Kçº¿æ•°æ®æŸ¥è¯¢"""
        query = select(MarketData).where(
            and_(
                MarketData.symbol == symbol,
                MarketData.timestamp >= start_time,
                MarketData.timestamp <= end_time
            )
        ).order_by(
            MarketData.timestamp.desc()
        ).limit(limit)
        
        result = await db.execute(query)
        return result.scalars().all()
```

### 2. ç¼“å­˜ä¼˜åŒ–
```python
from functools import wraps
import asyncio

def cache_result(expire_time: int = 300):
    """ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                return json.loads(cached_result)
            
            # æ‰§è¡Œå‡½æ•°
            result = await func(*args, **kwargs)
            
            # ç¼“å­˜ç»“æœ
            await redis_client.setex(
                cache_key, 
                expire_time, 
                json.dumps(result, default=str)
            )
            
            return result
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@cache_result(expire_time=60)
async def get_market_summary(symbol: str):
    """è·å–å¸‚åœºæ¦‚è¦ï¼ˆç¼“å­˜1åˆ†é’Ÿï¼‰"""
    return await market_service.get_summary(symbol)
```

### 3. å¼‚æ­¥ä¼˜åŒ–
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncOptimizer:
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=10)
    
    async def parallel_data_processing(self, symbols: List[str]):
        """å¹¶è¡Œå¤„ç†å¤šä¸ªè‚¡ç¥¨æ•°æ®"""
        tasks = []
        
        for symbol in symbols:
            task = asyncio.create_task(
                self.process_symbol_data(symbol)
            )
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return results
    
    async def cpu_intensive_task(self, data):
        """CPUå¯†é›†å‹ä»»åŠ¡å¼‚æ­¥å¤„ç†"""
        loop = asyncio.get_event_loop()
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒCPUå¯†é›†å‹ä»»åŠ¡
        result = await loop.run_in_executor(
            self.executor,
            self.heavy_calculation,
            data
        )
        
        return result
    
    def heavy_calculation(self, data):
        """é‡è®¡ç®—ä»»åŠ¡"""
        # NumPyå‘é‡åŒ–è®¡ç®—
        return np.complex_calculation(data)
```

